# open("review_.jl",'w').close()
# open("author_.jl",'w').close()
# open("book_.jl",'w').close()






# import os
# dir_path = os.path.dirname(os.path.realpath(__file__))
# text = open('test1.txt','w')
# w = text.write(dir_path)
# text.close()

# from GoodreadsScraper.spiders import review_spider
# from review_spider import ReviewSpider

# start_urls=['https://www.goodreads.com/review/list/62446163-patrick-walsh?order=d&ref=nav_mybooks&shelf=read','https://www.goodreads.com/review/list/62446163-patrick-walsh?order=d&ref=nav_mybooks&shelf=to-read','https://www.goodreads.com/review/list/62446163-patrick-walsh?order=d&ref=nav_mybooks&shelf=currently-reading']

# # referencing this variable in each of the other spiders

# # call the other spiders here

# #scrapy crawl review_spider

# test = ReviewSpider(start_urls)
# print(test)
